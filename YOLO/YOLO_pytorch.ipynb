{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2060', major=7, minor=5, total_memory=6143MB, multi_processor_count=30)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"datasets/signDatabasePublicFramesOnly/\"\n",
    "output = pd.read_csv(dataset_dir + \"allAnnotations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(anImg, aBoxes):\n",
    "    theImageWidth, theImageHeight = anImg.size\n",
    "    scale_x, scale_y = 416/theImageWidth, 416/theImageHeight\n",
    "    class_label, x1, y1, x2, y2 = aBoxes[0]\n",
    "\n",
    "    x1, x2 = x1 * scale_x, x2 * scale_x\n",
    "    y1, y2 = y1 * scale_y, y2 * scale_y\n",
    "\n",
    "    cx = (x1 + x2) / 2 / 416\n",
    "    cy = (y1 + y2) / 2 / 416\n",
    "    width = x2 - x1 / 416\n",
    "    height = y2 - y1 / 416\n",
    "\n",
    "    return anImg.resize((416,416)), torch.tensor([[class_label, cx, cy, width, height]])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LISA(Dataset):\n",
    "    \"This custom dataset was made using the data provided by the CVRR Laboratory at UCSD. More information can be found at https://cvrr.ucsd.edu/home\"\n",
    "    def __init__(self, csv_file, root_dir, S=7, B=2, C=47, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labels = {class_name: idx for idx, class_name in enumerate(self.annotations.iloc[:, 0].apply(lambda x: x.split(';')[1]).unique())}\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        theBoxes = []\n",
    "\n",
    "        theImgPath, *theBbox, _ = self.annotations.iloc[index, 0].split(\";\")\n",
    "        theBbox[0] = self.labels[theBbox[0]] # Convert to integer\n",
    "        theBbox[1:] = list(map(int, theBbox[1:])) # Class Name, Upper Left X, Lower Right X, Upper Left Y, Lower Right Y\n",
    "        theBoxes.append(theBbox)\n",
    "        theImgPath = os.path.join(self.root_dir, theImgPath)\n",
    "        theImg = Image.open(theImgPath)\n",
    "\n",
    "        theBoxes = torch.tensor(theBoxes)\n",
    "        if self.transform:\n",
    "            theImg, theBoxes = self.transform(theImg, theBoxes)\n",
    "\n",
    "        theLabels = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
    "\n",
    "        for theBox in theBoxes:\n",
    "            class_label, x, y, width, height = theBox.tolist()\n",
    "            class_label = int(class_label)\n",
    "\n",
    "            # i,j represents the cell row and cell column\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            \"\"\"\n",
    "            Calculating the width and height of cell of bounding box,\n",
    "            relative to the cell is done by the following, with\n",
    "            width as the example:\n",
    "            \n",
    "            width_pixels = (width*self.image_width)\n",
    "            cell_pixels = (self.image_width)\n",
    "            \n",
    "            Then to find the width relative to the cell is simply:\n",
    "            width_pixels/cell_pixels, simplification leads to the\n",
    "            formulas below.\n",
    "            \"\"\"\n",
    "            width_cell, height_cell = (\n",
    "                width * self.S,\n",
    "                height * self.S,\n",
    "            )\n",
    "\n",
    "            # If no object already found for specific cell i,j\n",
    "            # Note: This means we restrict to ONE object\n",
    "            # per cell!\n",
    "            if theLabels[i, j, 47] == 0:\n",
    "                # Set that there exists an object\n",
    "                theLabels[i, j, 47] = 1\n",
    "\n",
    "                # Box coordinates\n",
    "                box_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell, width_cell, height_cell]\n",
    "                )\n",
    "\n",
    "                theLabels[i, j, 48:52] = box_coordinates\n",
    "\n",
    "                # Set one hot encoding for class_label\n",
    "                theLabels[i, j, class_label] = 1\n",
    "\n",
    "        return theImg, theLabels\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "theDataset = LISA(dataset_dir + \"allAnnotations.csv\", dataset_dir, transform = preprocess)\n",
    "theImg, theLabels = theDataset.__getitem__(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
